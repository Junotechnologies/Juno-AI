# JunoAI - ML Model Training Repository

## ğŸ“‹ Project Overview

This repository contains three distinct machine learning approaches for predicting optimal device settings (Heat Level, TENS Mode, TENS Level) for JunoPlus therapy sessions. Each approach has been organized into its own folder with complete documentation and monthly improvement tracking.

## ğŸ“ Repository Structure

```
JunoAI/
â”œâ”€â”€ hierarchical_xgboost_approach/
â”‚   â”œâ”€â”€ hierarchical_classification_xgboost.ipynb
â”‚   â”œâ”€â”€ IMPROVEMENTS_REPORT.md
â”‚   â”œâ”€â”€ README.md
â”‚   â””â”€â”€ models/
â”‚       â””â”€â”€ hierarchical_approach/
â”œâ”€â”€ vertex_ai_training_approach/
â”‚   â”œâ”€â”€ vertex_ai_ml_training.ipynb
â”‚   â”œâ”€â”€ IMPROVEMENTS_REPORT.md
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ multioutput_deeplearning_approach/
â”‚   â”œâ”€â”€ multioutput_deeplearning_model.ipynb
â”‚   â”œâ”€â”€ IMPROVEMENTS_REPORT.md
â”‚   â”œâ”€â”€ README.md
â”‚   â””â”€â”€ models/
â”‚       â””â”€â”€ multioutput_approach/
â”œâ”€â”€ models/
â”‚   â””â”€â”€ (shared model artifacts)
â”œâ”€â”€ tens_prediction_api/
â”‚   â””â”€â”€ (API deployment files)
â””â”€â”€ README.md (this file)
```

## ğŸ¯ Approach Comparison

| Approach | Heat | Mode | Level | Avg | Training Time | Deployment |
|----------|------|------|-------|-----|--------------|------------|
| **XGBoost Hierarchical** | ğŸ¥‡ **100%** | 59.2% | 67.1% | 75.4% | ~5 min | Easy |
| **Vertex AI BigQuery ML** | N/A | N/A | MAE: 1.18 | - | ~2 min | Cloud-Only |
| **Deep Learning Multi-Output** | 98.2% | ğŸ¥‡ **94.5%** | ğŸ¥‡ **72.8%** | ğŸ¥‡ **88.5%** | ~12 min | Medium |

### ğŸ† Winner by Category

- **Best Heat Level**: XGBoost (100% accuracy)
- **Best TENS Mode**: Deep Learning (94.5% accuracy)
- **Best TENS Level**: Deep Learning (72.8% accuracy)
- **Best Overall**: Deep Learning (88.5% average accuracy)
- **Best Interpretability**: XGBoost (feature importance)
- **Best Scalability**: Vertex AI (serverless, BigQuery integration)
- **Fastest Training**: Vertex AI (~2 minutes)
- **Fastest Inference**: XGBoost (<10ms per prediction)

## ğŸ“Š Detailed Approach Breakdowns

### 1. Hierarchical XGBoost Classification

**Best for**: Interpretability, fast inference, perfect heat level prediction

**Architecture**: Two-stage hierarchical prediction
- Stage 1: Independent Heat and Mode classifiers
- Stage 2: Conditional TENS Level prediction (only when Mode > 0)

**Key Features**:
- âœ… Perfect 100% Heat Level accuracy
- âœ… High feature importance interpretability
- âœ… Sub-millisecond inference time
- âœ… Standard pickle format (easy deployment)
- âš ï¸ TENS Mode needs improvement (59.2%)

**See**: `hierarchical_xgboost_approach/README.md` for details

---

### 2. Vertex AI ML Training

**Best for**: Cloud-native deployment, BigQuery integration, scalability

**Architecture**: BigQuery ML BOOSTED_TREE_REGRESSOR
- Direct training on BigQuery data
- Vertex AI experiment tracking
- SQL-based inference via TABLE FUNCTION

**Key Features**:
- âœ… Serverless training and inference
- âœ… Native BigQuery integration (no data movement)
- âœ… Automated experiment tracking
- âœ… Scalable to millions of predictions/day
- âš ï¸ Primarily single-output (TENS Level focus)

**See**: `vertex_ai_training_approach/README.md` for details

---

### 3. Multi-Output Deep Learning

**Best for**: Overall accuracy, unified predictions, capturing inter-dependencies

**Architecture**: Shared neural network with task-specific heads
- 3-layer shared base (256 â†’ 128 â†’ 64)
- 3 independent output heads (Heat, Mode, Level)
- Multi-task learning with batch normalization

**Key Features**:
- âœ… Highest average accuracy (88.5%)
- âœ… Best TENS Mode (94.5%) and Level (72.8%)
- âœ… Single unified model
- âœ… Captures inter-task relationships
- âš ï¸ Slightly lower Heat accuracy vs XGBoost (98.2% vs 100%)

**See**: `multioutput_deeplearning_approach/README.md` for details

---

## ğŸ“ˆ Monthly Improvement Tracking

Each approach folder contains an `IMPROVEMENTS_REPORT.md` file with:
- **Monthly changelog** (grouped by year-month)
- **Performance metrics** before and after changes
- **Detailed analysis** of what worked and what didn't
- **Lessons learned** from each iteration
- **Future optimization ideas** prioritized

### Report Format

```markdown
# [Approach Name] - Monthly Improvements Report

## ğŸ“… December 2024

### Version X.X - [Change Description] (Date)

**Summary**: Brief overview

#### Changes Implemented
- Detailed changes

#### Performance Results
- Metrics and comparisons

#### Key Insights
- Lessons learned
```

## ğŸš€ Quick Start

### 1. Choose Your Approach

**Need maximum interpretability?** â†’ Use XGBoost Hierarchical  
**Deploying on Google Cloud?** â†’ Use Vertex AI  
**Want best overall accuracy?** â†’ Use Multi-Output Deep Learning  

### 2. Open the Notebook

```bash
# Navigate to the approach folder
cd [approach_folder_name]

# Open Jupyter notebook
jupyter notebook [notebook_name].ipynb
```

### 3. Review Improvements

```bash
# Read the improvements report
cat IMPROVEMENTS_REPORT.md
```

## ğŸ”§ Requirements

### All Approaches
- Python 3.8+
- pandas
- numpy
- scikit-learn

### XGBoost Approach
- lightgbm
- matplotlib
- seaborn

### Vertex AI Approach
- google-cloud-bigquery
- google-cloud-aiplatform

### Deep Learning Approach
- tensorflow 2.x
- keras
- matplotlib
- plotly

## ğŸ“š Documentation

Each approach folder contains:
1. **README.md** - Overview, architecture, usage examples
2. **IMPROVEMENTS_REPORT.md** - Monthly changelog with performance tracking
3. **Jupyter Notebook** - Complete training pipeline
4. **Models folder** - Saved artifacts

## ğŸ¯ Recommendation Matrix

| Use Case | Recommended Approach | Reason |
|----------|---------------------|--------|
| Production deployment (accuracy priority) | Deep Learning | Best overall performance (88.5%) |
| Production deployment (speed priority) | XGBoost | Fastest inference (<10ms) |
| Cloud-native architecture | Vertex AI | Serverless, scalable, BigQuery native |
| Research & experimentation | All three | Compare and ensemble |
| Interpretability required | XGBoost | Feature importance analysis |
| Consistent multi-output predictions | Deep Learning | Unified architecture |

## ğŸ—ï¸ Ensemble Strategy (Recommended)

For maximum reliability, consider an ensemble approach:

1. **Heat Level**: Use XGBoost (100% accuracy)
2. **TENS Mode**: Use Deep Learning (94.5% accuracy)
3. **TENS Level**: Ensemble average of Deep Learning + XGBoost

This hybrid strategy leverages the strengths of each approach.

## ğŸ“ Contact & Contributions

For questions, improvements, or contributions, please:
1. Review the appropriate approach folder
2. Check the IMPROVEMENTS_REPORT.md for context
3. Follow the established monthly tracking format

---

**Last Updated**: December 5, 2024  
**Repository Status**: âœ… Active Development  
**Latest Version**: All approaches at v2.0 or v1.0
